# !/usr/bin/env python3
"""
Created on Fri Jun 26 08:37:56 2020

Analyzer code that attempts to determine BIDS
from dcm2niix NIFTI/JSON output

@author: dlevitas
"""

from __future__ import division
import os, sys, re, json, warnings
import pandas as pd
import numpy as np
import nibabel as nib
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
plt.style.use('dark_background')
from operator import itemgetter
from math import floor

warnings.filterwarnings("ignore")

data_dir = sys.argv[1]
os.chdir(data_dir)


######## Functions ########
def correctPE(pe_direction, ornt):
    '''
    Takes pe_direction and image orientation to correct pe_direction
    if need be. Correction occurs if the pe_direction is "xyz". Otherwise,
    no correction is necessary.

    Based on https://github.com/nipreps/fmriprep/issues/2341 and original code
    comes from Chris Markiewicz and Mathias Goncalves

    Parameters
    ----------
    pe_direction : string
        Value from PhaseEncodingDirection in json file generated by dcm2niix
    ornt: string
        Value of ''.join(nib.aff2axcodes(nii_img.affine))

    Returns
    -------
    proper_pe_direction: string
        Either input pe_direction (if ijk), or corrected pe_direction (if xyz)
    '''

    axes = (("R", "L"), ("A", "P"), ("S", "I"))
    proper_ax_idcs = {"i": 0, "j": 1, "k": 2}

    # pe_direction is ijk (no correction necessary)
    if any(x in pe_direction for x in ['i','i-','j','j-','k','k']):
        proper_pe_direction = pe_direction

    # pe_direction xyz (correction required)
    else:

        improper_ax_idcs = {"x": 0, "y": 1, "z": 2}
        axcode = ornt[improper_ax_idcs[pe_direction[0]]]
        axcode_index = improper_ax_idcs[pe_direction[0]]
        inv = pe_direction[1:] == "-"

        if pe_direction[0] == 'x':
            if 'L' in axcode:
                inv = not inv
        elif pe_direction[0] == 'y':
            if 'P' in axcode:
                inv = not inv
        elif pe_direction[0] == 'z':
            if 'I' in axcode:
                inv = not inv
        else:
            ValueError('pe_direction does not contain letter i, j, k, x, y, or z')

        if inv:
            polarity = '-'
        else:
            polarity = ''

        proper_pe_direction = [key for key, value in proper_ax_idcs.items() if value == axcode_index][0] + polarity

    return proper_pe_direction


def determineDir(pe_direction, ornt):
    '''
    Takes pe_direction and image orientation to determine direction
    required by BIDS "_dir-" label

    Based on https://github.com/nipreps/fmriprep/issues/2341 and original code
    comes from Chris Markiewicz and Mathias Goncalves

    Parameters
    ----------
    pe_direction : string
        Value from PhaseEncodingDirection in json file generated by dcm2niix
    ornt: string
        Value of ''.join(nib.aff2axcodes(nii_img.affine))

    Returns
    -------
    direction: string
        direction for BIDS "_dir-" label
    '''

    axes = (("R", "L"), ("A", "P"), ("S", "I"))
    ax_idcs = {"i": 0, "j": 1, "k": 2}
    axcode = ornt[ax_idcs[pe_direction[0]]]
    inv = pe_direction[1:] == "-"

    if pe_direction[0] == 'i':
        if 'L' in axcode:
            inv = not inv
    elif pe_direction[0] == 'j':
        if 'P' in axcode:
            inv = not inv
    elif pe_direction[0] == 'k':
        if 'I' in axcode:
            inv = not inv

    for ax in axes:
        for flip in (ax, ax[::-1]):
            if flip[not inv].startswith(axcode):
                direction = "".join(flip)

    return direction


def add_dirList(dir_list):
    '''
    Filters the json list generated by preprocess.sh to ensure that the JSON
    files are generated via dcm2niix, and that they contain corresponding nifti
    (and bval/bvec) files. If these conditions are satisfied, all files are
    added to a modified dir_list

    Parameters
    ----------
    dir_list : pd.DataFrame
        DataFrame of json files generated from preprocess.sh

    Returns
    -------
    new_dir_list: list
        all files (i.e json, nifti, (bval/bvec)) from uploaded dataset
    '''

    new_dir_list = []

    # Load JSON list and find corresponding nifti (and bval/bvec files)
    dir_list.columns = ['path']

    # Remove Philips proprietary files in dir_list if they exist
    dir_list = dir_list[~dir_list.path.str.contains('PARREC|Parrec|parrec')].reset_index(drop=True)

    # Get list of json files
    json_list = sorted([x for x in dir_list['path']])

    # Parse through nifti and json data for pertinent information
    for j in range(len(json_list)):
        json_data = open(json_list[j])
        json_data = json.load(json_data, strict=False)


        # Only want json files with corresonding nifti (and bval/bvec) and if the files come from dcm2niix
        if 'ConversionSoftware' in json_data and json_data['ConversionSoftware'] == 'dcm2niix':
            if len([os.path.dirname(json_list[j]) + '/' + x for x in os.listdir(os.path.dirname(json_list[j])) if os.path.basename(json_list[j])[:-4] in x]) > 1:
                new_dir_list.append([os.path.dirname(json_list[j]) + '/' + x for x in os.listdir(os.path.dirname(json_list[j])) if os.path.basename(json_list[j][:-4]) in x])

    # Flatten list of lists
    new_dir_list = [file for sublist in new_dir_list for file in sublist]

    return new_dir_list


def select_unique_data(dir_list):
    '''
    Takes list of nifti, json, and bval/bvec files generated frm dcm2niix to find the
        unique data within the entire list. The contents of the list can be data
        from an entire dataset, a single subject, etc

    Parameters
    ----------
    dir_list : pd.DataFrame()
        List of nifti, json, and bval/bvec files generated from dcm2niix

    Returns
    -------
    data_list_unique_series: list
        List of dictionaries containing pertinent and unique information about the
            data, primarily coming from the metadata in the json files

    subjectIDs_info: list
        List of dictionaries containing subject identification info, such as
        PatientID, PatientName, PatientBirthDatge

    acquisition_dates: list
        List of dictionaries containing the AcquisitionDate and session #  (if applicable)
    '''

    # Create list for appending dictionaries to
    data_list = []

    # Get separate nifti and json (i.e. sidecar) lists
    json_list = [x for x in dir_list if '.json' in x]
    nifti_list = [x for x in dir_list if '.nii.gz' in x or '.bval' in x or '.bvec' in x]

    print('Determining unique acquisitions in list')
    print('------------------------------------------')
    for j in range(len(json_list)):
        json_data = open(json_list[j])
        json_data = json.load(json_data, strict=False)

        corresponding_nifti = [x for x in nifti_list if json_list[j][:-4] in x if 'nii.gz' in x][0]

        #Phase encoding direction info
        try:
            pe_direction = json_data['PhaseEncodingDirection']
        except:
            pe_direction = None

        try:
            ornt = nib.aff2axcodes(nib.load(corresponding_nifti).affine)
            ornt = ''.join([x for x in ornt])
        except:
            ornt = None

        if pe_direction is not None and ornt is not None:
            proper_pe_direction = correctPE(pe_direction, ornt)
            PED = determineDir(proper_pe_direction, ornt)
        else:
            PED = ''


        # Select SeriesNumbers
        SN = json_data['SeriesNumber']

        # Nifti (and bval/bvec) file(s) associated with specific json file
        nifti_paths_for_json = [x for x in nifti_list if json_list[j][:-4] in x]
        nifti_paths_for_json = [x for x in nifti_paths_for_json if '.json' not in x]

        # Find nifti file size
        filesize = os.stat(nifti_paths_for_json[0]).st_size

        # Find StudyID from json
        if 'StudyID' in json_data:
            studyID = json_data['StudyID']
        else:
            studyID = ''

        # Find subjectID from json (some files contain neither PatientName nor PatientID)
        if 'PatientName' in json_data:
            PatientName = json_data['PatientName']
        else:
            PatientName = os.path.dirname(json_list[j])

        if 'PatientID' in json_data:
            PatientID = json_data['PatientID']
        else:
            PatientID = os.path.basename(json_list[j])

        # Find PatientBirthDate
        if 'PatientBirthDate' in json_data:
            PatientBirthDate = json_data['PatientBirthDate'].replace('-','')
        else:
            PatientBirthDate = '00000000'

        # Find PatientSex
        if 'PatientSex' in json_data:
            PatientSex = json_data['PatientSex']
            if PatientSex not in ['M','F']:
                PatientSex = 'N/A'
        else:
            PatientSex = 'N/A'

        # Select subjectID to display to ezBIDS users
        # Precedence order: PatientName > PatientID > PatientBirthDate
        if PatientName:
            subject = PatientName
        elif PatientID:
            subject = PatientID
        elif PatientBirthDate:
            subject = PatientBirthDate

        subject = re.sub('[^A-Za-z0-9]+', '', subject)
        if not subject:
            subject = 'NA'

        # Find Acquisition Date & Time
        if 'AcquisitionDateTime' in json_data:
            AcquisitionDate = json_data['AcquisitionDateTime'].split('T')[0]
            AcquisitionTime = json_data['AcquisitionDateTime'].split('T')[-1]
        else:
            AcquisitionDate = '0000-00-00'
            AcquisitionTime = None

        # Find RepetitionTime
        if 'RepetitionTime' in json_data:
            RepetitionTime = json_data['RepetitionTime']
        else:
            RepetitionTime = 'N/A'

        # Find EchoNumber
        if 'EchoNumber' in json_data:
            EchoNumber = json_data['EchoNumber']
        else:
            EchoNumber = None

        # Find EchoTime
        if 'EchoTime' in json_data:
            EchoTime = json_data['EchoTime']*1000
        else:
            EchoTime = 0

        # Find MultibandAccerationFactor
        if 'MultibandAccelerationFactor' in json_data:
            MultibandAccelerationFactor = json_data['MultibandAccelerationFactor']
        else:
            MultibandAccelerationFactor = 'N/A'

        # Find how many volumes are in jsons's corresponding nifti file
        try:
            volume_count = nib.load(json_list[j][:-4] + 'nii.gz').shape[3]
        except:
            volume_count = 1

        # Relative paths of json and nifti files (per SeriesNumber)
        paths = sorted(nifti_paths_for_json + [json_list[j]])

        # Organize all from individual SeriesNumber in dictionary
        mapping_dic = {'StudyID': studyID,
                       'PatientName': PatientName,
                       'PatientID': PatientID,
                       'PatientBirthDate': PatientBirthDate,
                       'PatientSex': PatientSex,
                       'PatientAge': 'N/A',
                       'subject': subject,
                       'session': '',
                       'SeriesNumber': json_data['SeriesNumber'],
                       'AcquisitionDate': AcquisitionDate,
                       'AcquisitionTime': AcquisitionTime,
                       'SeriesDescription': json_data['SeriesDescription'],
                       'ProtocolName': json_data['ProtocolName'],
                       'ImageType': json_data['ImageType'],
                       'SeriesNumber': json_data['SeriesNumber'],
                       'RepetitionTime': RepetitionTime,
                       'EchoNumber': EchoNumber,
                       'EchoTime': EchoTime,
                       'MultibandAccelerationFactor': MultibandAccelerationFactor,
                       'DataType': '',
                       'ModalityLabel': '',
                       'series_idx': 0,
                       'direction': PED,
                       'TaskName': '',
                       "exclude": False,
                       'filesize': filesize,
                       "NumVolumes": volume_count,
                       "forType": '',
                       'error': None,
                       'section_ID': 1,
                       'message': '',
                       'br_type': '',
                       'nifti_path': [x for x in nifti_paths_for_json if '.nii.gz' in x][0],
                       'json_path': json_list[j],
                       'paths': paths,
                       'pngPath': '',
                       'headers': '',
                       'sidecar':json_data
                       }
        data_list.append(mapping_dic)

    # Curate subjectID and acquisition date info to display in UI
    subjectIDs_info = list({x['subject']:{'subject':x['subject'], 'PatientID':x['PatientID'], 'PatientName':x['PatientName'], 'PatientBirthDate':x['PatientBirthDate'], 'phenotype':{'sex':x['PatientSex'], 'age':x['PatientAge']}, 'exclude': False, 'sessions': []} for x in data_list}.values())


    subjectIDs_info = sorted(subjectIDs_info, key = lambda i: i['subject'])

    acquisition_dates = list({(x['subject'], x['AcquisitionDate']):{'subject':x['subject'], 'AcquisitionDate':x['AcquisitionDate'], 'session': ''} for x in data_list}.values())
    acquisition_dates = sorted(acquisition_dates, key = lambda i: i['AcquisitionDate'])

    # Insert sessions info if applicable
    subject_session = [[x['subject'], x['AcquisitionDate'], x['session']] for x in data_list]
    subject_session = sorted([list(x) for x in set(tuple(x) for x in subject_session)], key = lambda i: i[1])

    for i in np.unique(np.array([x[0] for x in subject_session])):
        subject_indices = [x for x,y in enumerate(subject_session) if y[0] == i]
        if len(subject_indices) > 1:
            for j, k in enumerate(subject_indices):
                subject_session[k][-1] = str(j+1)

    subject_session = sorted([list(x) for x in set(tuple(x) for x in subject_session)], key = lambda i: i[1])

    for x,y in enumerate(acquisition_dates):
        y['session'] = subject_session[x][-1]

    for si in range(len(subjectIDs_info)):
        for ss in subject_session:
            if ss[0] == subjectIDs_info[si]['subject']:
                subjectIDs_info[si]['sessions'].append({'AcquisitionDate': ss[1], 'session': ss[2], 'exclude': False})
        subjectIDs_info[si].update({'validationErrors': []})

    # Sort list of dictionaries by subject, AcquisitionDate, SeriesNumber, and json_path
    data_list = sorted(data_list, key=itemgetter('subject', 'AcquisitionDate', 'SeriesNumber', 'json_path'))

    # Add session info to data_list, if applicable
    for i in range(len(acquisition_dates)):
        for j in range(len(data_list)):
            if data_list[j]['subject'] == acquisition_dates[i]['subject'] and data_list[j]['AcquisitionDate'] == acquisition_dates[i]['AcquisitionDate']:
                data_list[j]['session'] = acquisition_dates[i]['session']

    # Unique data is determined from 4 dicom header values: SeriesDescription, EchoTime, ImageType, MultibandAccelerationFactor
    # If EchoTime values differ slightly (>< 1) and other values are the same, don't give new unique series ID
    data_list_unique_series = []
    series_tuples = []
    series_idx = 0

    for x in range(len(data_list)):
        """
        If retro-reconstruction (RR) acquistions are found ("_RR" in SeriesDescription),
        they should be part of same unique series as non retro-reconstruction ones.
        """
        if '_RR' in data_list[x]['SeriesDescription']:
            modified_SD = data_list[x]['SeriesDescription'].replace('_RR', '')
            unique_items = [data_list[x]['EchoTime'], modified_SD, data_list[x]['ImageType'], data_list[x]['MultibandAccelerationFactor'], 1]
        else:
            unique_items = [data_list[x]['EchoTime'], data_list[x]['SeriesDescription'], data_list[x]['ImageType'], data_list[x]['MultibandAccelerationFactor'], 1]

        if x == 0:
            data_list[x]['series_idx'] = 0
            data_list_unique_series.append(data_list[x])

        elif tuple(unique_items) not in [y[:-1] for y in series_tuples]:
            echo_time = unique_items[0]
            rest = unique_items[1:]
            if tuple(rest) in [y[1:-1] for y in series_tuples]:
                common_series_index = [y[1:-1] for y in series_tuples].index(tuple(rest))

                if not series_tuples[common_series_index][0]-1 <= echo_time <= series_tuples[common_series_index][0]+1:
                    unique_items[-1] = 0
                    series_idx += 1
                    data_list[x]['series_idx'] = series_idx
                    data_list_unique_series.append(data_list[x])
                else:
                    data_list[x]['series_idx'] = series_tuples[common_series_index][-1]
            else:
                series_idx += 1
                data_list[x]['series_idx'] = series_idx
                data_list_unique_series.append(data_list[x])

        else:
            common_index = [y[1:-1] for y in series_tuples].index(tuple(unique_items[1:]))
            data_list[x]['series_idx'] = series_tuples[common_index][-1]

        tup = tuple(unique_items + [series_idx])
        series_tuples.append(tup)


    return data_list, data_list_unique_series, subjectIDs_info, acquisition_dates


def identify_series_info(data_list_unique_series):
    '''
    Takes list of dictionaries with key and unique information, and uses it to
        determine the DataType and Modality labels of the unique acquisitions.
        Other information (e.g. run, acq, ce) will be determined if the data
        follows the ReproIn naming convention for SeriesDescriptions.

    Parameters
    ----------
    data_list_unique_series : list
        List of dictionaries continaing key information about the data

    Returns
    -------
    series_list: list
        List of dictionaries containing pertinent about the unique acquisitions.
        This information is displayed to the user through the UI, which grabs
        this information.
    '''


    # Determine DataType, ModalityLabel, and labels of series list acquisitions
    series_list = []
    for i, series in enumerate(data_list_unique_series):

        series_entities = {}
        SD = series['SeriesDescription']
        image_type = series['ImageType']
        EchoTime = series['EchoTime']
        TR = series['RepetitionTime']

        if 'SequenceName' in series['sidecar']:
            SequenceName = series['sidecar']['SequenceName']
        elif 'ScanningSequence' in series['sidecar']:
            SequenceName = series['sidecar']['ScanningSequence']
        else:
            SequenceName = 'N/A'

        # Populate some labels fields (based on ReproIn convention)
        if 'sub-' in SD:
            series_entities['subject'] = SD.split('sub-')[-1].split('_')[0]
        else:
            series_entities['subject'] = None

        if '_ses-' in SD:
            series_entities['session'] = SD.split('_ses-')[-1].split('_')[0]
        else:
            series_entities['session'] = None

        if '_run-' in SD:
            series_entities['run'] = SD.split('_run-')[-1].split('_')[0]
            if series_entities['run'][0] == '0':
                series_entities['run'] = series_entities['run'][1:]
        else:
            series_entities['run'] = ''

        if '_task-' in SD:
            series_entities['task'] = SD.split('_task-')[-1].split('_')[0]
        else:
            pass

        if '_dir-' in SD:
            series_entities['direction'] = SD.split('_dir-')[-1].split('_')[0]
        else:
            series_entities['direction'] = ''

        if '_acq-' in SD:
            series_entities['acquisition'] = SD.split('_acq-')[-1].split('_')[0]
        else:
            series_entities['acquisition'] = ''

        if '_ce-' in SD:
            series_entities['ceagent'] = SD.split('_ce-')[-1].split('_')[0]
        else:
            series_entities['ceagent'] = ''

        if '_echo-' in SD:
            series_entities['echo'] = SD.split('_echo-')[-1].split('_')[0]
            if series_entities['echo'][0] == '0':
                series_entities['echo'] = series_entities['echo'][1:]
        else:
            series_entities['echo'] = ''

        if '_fa-' in SD:
            series_entities['fa'] = SD.split('_fa-')[-1].split('_')[0]
        else:
            series_entities['fa'] = ''

        if '_inv-' in SD:
            series_entities['inversion'] = SD.split('_inv-')[-1].split('_')[0]
            if series_entities['inversion'][0] == '0':
                series_entities['inversion'] = series_entities['inversion'][1:]
        else:
            series_entities['inversion'] = ''

        if '_part-' in SD:
            series_entities['part'] = SD.split('_part-')[-1].split('_')[0]
        else:
            series_entities['part'] = ''


        # Make easier to find key characters/phrases in SD by removing non-alphanumeric characters and make everything lowercase
        SD = re.sub('[^A-Za-z0-9]+', '', SD).lower()

        # Keys for helping determine acquisition types, based on SeriesDescription
        localizer_keys = ['localizer','scout']
        asl_keys = ['asl']
        angio_keys = ['angio']
        se_magPhase_fmap_keys = ['fmap','fieldmap','spinecho','sefmri','semri']
        flair_keys = ['flair','t2spacedafl']
        dwi_derived_keys = ['trace','fa','adc']
        dwi_keys = ['dti','dwi','dmri']
        func_keys = ['bold','func','fmri','epi','mri','task','rest']
        func_rest_keys = ['rest','rsfmri','fcmri']
        t1w_keys = ['t1w','tfl3d','mprage','spgr','tflmgh']
        t2w_keys = ['t2w','t2']
        additional_anat_keys = ['t2starw','inplanet1','inplanet2','pdt2','pdw']
        anat_parametric_keys = ['pdt2map','t2starmap','r2starmap',
                                'mwfmap','mtvmap','chimap','tb1map',
                                'pdmap','mtrmap','mtsat','t1rho',
                                'rb1map','s0map','m0map','t1map','r1map','t2map','r2map']

        # # #  Determine DataTypes and ModalityLabels # # # # # # #

        # Localizers
        if any(x in SD for x in localizer_keys):
            series['error'] = 'Acquisition appears to be a localizer'
            series['message'] = 'Acquisition is believed to be a localizer because "{}" is in the SeriesDescription. Please modify if incorrect.'.format([x for x in localizer_keys if re.findall(x,SD)][0])
            series['br_type'] = 'exclude (localizer)'

        # Arterial Spin Labeling (ASL)
        elif any(x in SD for x in asl_keys):
            series['br_type'] = 'exclude'
            series['DataType'] = 'asl'
            series['ModalityLabel'] = 'asl'
            series['error'] = 'Acqusition appears to be ASL, which is currently not supported by ezBIDS at this time, but will be in the future'
            series['message'] = 'Acquisition is believed to be asl/asl because "{}" is in the SeriesDescription. Please modify if incorrect. Currently, ezBIDS does not support ASL conversion to BIDS'.format([x for x in asl_keys if re.findall(x,SD)][0])

        # Angiography
        elif any(x in SD for x in angio_keys):
            series['br_type'] = 'exclude'
            series['DataType'] = 'anat'
            series['ModalityLabel'] = 'angio'
            series['error'] = 'Acqusition appears to be an Angiography acquisition, which is currently not supported by ezBIDS at this time, but will be in the future'
            series['message'] = 'Acquisition is believed to be anat/angio because "{}" is in the SeriesDescription. Please modify if incorrect. Currently, ezBIDS does not support Angiography conversion to BIDS'.format([x for x in angio_keys if re.findall(x,SD)][0])

        # Magnitude/Phase[diff] and Spin Echo (SE) field maps
        elif any(x in SD for x in se_magPhase_fmap_keys):
            series['DataType'] = 'fmap'
            series['forType'] = 'func/bold'
            if 'REAL' in series['ImageType']:
                series_entities['part'] = 'real'
            if 'IMAGINARY' in series['ImageType']:
                series_entities['part'] = 'imag'

            # Magnitude/Phase[diff] field maps
            if 'EchoNumber' in series['sidecar']:
                if any(x in series['json_path'] for x in ['_real.','_imaginary.']):
                    series['error'] = 'Acquisition appears to be a real or imaginary field map that needs to be manually adjusted to magnitude and phase (ezBIDS currently does not have this functionality). This acqusition will not be converted'
                    series['message'] = series['error']
                    series['br_type'] = 'exclude'
                elif series['EchoNumber'] == 1 and '_e1_ph' not in series['json_path']:
                    series['ModalityLabel'] = 'magnitude1'
                    series['message'] = 'Acquisition is believed to be fmap/magnitude1 because "{}" is in SeriesDescription, EchoNumber == 1 in metadata, and the phrase "_e1_ph" is not in the filename. Please modify if incorrect'.format([x for x in se_magPhase_fmap_keys if re.findall(x,SD)][0])
                elif series['EchoNumber'] == 1 and '_e1_ph' in series['json_path']:
                    series['ModalityLabel'] = 'phase1'
                    series['message'] = 'Acquisition is believed to be fmap/phase1 because "{}" is in SeriesDescription, EchoNumber == 1 in metadata, and the phrase "_e1_ph" is in the filename. Please modify if incorrect'.format([x for x in se_magPhase_fmap_keys if re.findall(x,SD)][0])
                elif series['EchoNumber'] == 2 and '_e2_ph' not in series['json_path']:
                    series['ModalityLabel'] = 'magnitude2'
                    series['message'] = 'Acquisition is believed to be fmap/magnitude2 because "{}" is in SeriesDescription, EchoNumber == 2 in metadata, and the phrase "_e2_ph" is not in the filename. Please modify if incorrect'.format([x for x in se_magPhase_fmap_keys if re.findall(x,SD)][0])
                elif series['EchoNumber'] == 2 and '_e2_ph' in series['json_path'] and '_e1_ph' in data_list_unique_series[i-2]['json_path']:
                    series['ModalityLabel'] = 'phase2'
                    series['message'] = 'Acquisition is believed to be fmap/phase2 because "{}" is in SeriesDescription, EchoNumber == 2 in metadata, and the phrase "_e2_ph" is in the filename and "_e1_ph" the one two before. Please modify if incorrect'.format([x for x in se_magPhase_fmap_keys if re.findall(x,SD)][0])
                elif series['EchoNumber'] == 2 and '_e2_ph' in series['json_path'] and '_e1_ph' not in data_list_unique_series[i-2]['json_path']:
                    series['ModalityLabel'] = 'phasediff'
                    series['message'] = 'Acquisition is believed to be fmap/phasediff because "fmap" or "fieldmap" is in SeriesDescription, EchoNumber == 2 in metadata, and the subjectstring "_e2_ph" is in the filename but "_e1_ph" not found in the acquisition two before. Please modify if incorrect'
                else:
                    series['error'] = 'Acquisition appears to be some form of fieldmap with an EchoNumber, however, unable to determine if it is a magnitude, phase, or phasediff. Please modify if acquisition is desired for BIDS conversion, otherwise the acqusition will not be converted'
                    series['message'] = series['error']
                    series['br_type'] = 'exclude'

            # Spin echo field maps
            else:
                series['ModalityLabel'] = 'epi'
                series['message'] = 'Acquisition is believed to be fmap/epi because "{}" is in SeriesDescription, and does not contain metadata info associated with magnitude/phasediff acquisitions. Please modify if incorrect'.format([x for x in se_magPhase_fmap_keys if re.findall(x,SD)][0])
                series_entities['direction'] = series['direction']

        # DWI
        elif 'DIFFUSION' in series['ImageType'] and 'b0' in SD:
            series['DataType'] = 'fmap'
            series['ModalityLabel'] = 'epi'
            series['forType'] = 'dwi/dwi'
            series_entities['direction'] = series['direction']
            series['message'] = 'Acquisition appears to be a fmap/epi meant for dwi/dwi, as "DIFFUSION" is in ImageType, and "b0" is in the SeriesDescription. Please modify if incorrect'

        elif not any('.bvec' in x for x in series['paths']) and 'DIFFUSION' in series['ImageType']:
            series['error'] = 'Acquisitions has "DIFFUSION" label in the ImageType; however, there are no corresponding bval/bvec files. This may or may not be dwi/dwi. Please modify if incorrect.'
            series['message'] = series['error']
            series['br_type'] = 'exclude'

        elif any('.bvec' in x for x in series['paths']):
            if 'DIFFUSION' not in series['ImageType']:
                if series['NumVolumes'] < 2:
                    if any(x in SD for x in flair_keys):
                        series['DataType'] = 'anat'
                        series['ModalityLabel'] = 'FLAIR'
                        series['message'] = 'Acquisition is believed to be anat/FLAIR because "{}" is in the SeriesDescription. Please modify if incorrect'.format([x for x in flair_keys if re.findall(x,SD)][0])
                    elif 't2w' in SD:
                        series['DataType'] = 'anat'
                        series['ModalityLabel'] = 'T2w'
                        series['message'] = 'Acquisition is believed to be anat/T2w because "t2w" is in the SeriesDescription. Please modify if incorrect'
                    else:
                        series['error'] = 'Acquisition has bval and bvec files but does not appear to be dwi/dwi because "DIFUSSION" is not in ImageType and contains less than 2 volumes. Please modify if incorrect, otherwise will not convert to BIDS'
                        series['message'] = series['error']
                        series['br_type'] = 'exclude'
                else:
                    series['DataType'] = 'dwi'
                    series['ModalityLabel'] = 'dwi'
                    series['message'] = 'Acquisition appears to be dwi/dwi because although "DIFUSSION" is not in ImageType, the acquisition has bval and bvec files and has {} volumes. Please modify if incorrect'.format(series['NumVolumes'])
                    series_entities['direction'] = series['direction']
            else:
                # low b-values will default to fmap/epi, intended to be used on dwi/dwi data
                bval = np.loadtxt([x for x in series['paths'] if 'bval' in x][0])
                if np.max(bval) <= 50:
                    series['DataType'] = 'fmap'
                    series['ModalityLabel'] = 'epi'
                    series_entities['direction'] = series['direction']
                    series['forType'] = 'dwi/dwi'
                    series['message'] = 'Acquisition appears to be fmap/epi meant for dwi/dwi, as there are bval & bvec files, but with low b-values. Please modify if incorrect'

                # elif any(x in SD for x in dwi_derived_keys) and not any(x in SD for x in dwi_keys):
                elif any(x in SD for x in dwi_derived_keys):
                    series['error'] = 'Acquisition appears to be a TRACE, FA, or ADC, which are unsupported by ezBIDS and will therefore not be converted'
                    series['message'] = 'Acquisition is believed to be TRACE, FA, or ADC because there are bval & bvec files with the same SeriesNumber, and "{}" are in the SeriesDescription. Please modify if incorrect'.format([x for x in dwi_derived_keys if re.findall(x,SD)][0])
                    series['br_type'] = 'exclude'
                else:
                    series['DataType'] = 'dwi'
                    series['ModalityLabel'] = 'dwi'
                    series_entities['direction'] = series['direction']
                    series['message'] = 'Acquisition is believed to be dwi/dwi because there are bval & bvec files with the same SeriesNumber, "DIFFUSION" in ImageType, and does not appear to be derived dwi data. Please modify if incorrect'

        # DWI derivatives or other non-BIDS diffusion offshoots
        elif any(x in SD for x in dwi_derived_keys) and any(x in SD for x in dwi_keys):
            series['error'] = 'Acquisition appears to be a TRACE, FA, or ADC, which are unsupported by ezBIDS and will therefore not be converted'
            series['message'] = 'Acquisition is believed to be TRACE, FA, or ADC because there are bval & bvec files with the same SeriesNumber, and dwi-derived information present. Please modify if incorrect'
            series['br_type'] = 'exclude'

        # Functional bold and phase
        elif any(x in SD for x in func_keys) and 'sbref' not in SD:
            if series['NumVolumes'] < 50:
                series['br_type'] = 'exclude'
                series['message'] = 'Acquisition appears to be functional but contain less than 50 volumes, suggesting a failure/restart, or possibly a test acquisition. Please modify if incorrect'
            else:
                series['DataType'] = 'func'
                if any(x in SD for x in func_rest_keys):
                    series_entities['task'] = 'rest'
                    series['message'] = 'Acquisition is believed to be func/bold because "{}" is in the SeriesDescription (but not "sbref"). Please modify if incorrect'.format([x for x in func_keys if re.findall(x,SD)][0])
                if 'MOSAIC' and 'PHASE' in series['ImageType']:
                    series['ModalityLabel'] = 'bold'
                    series_entities['part'] = 'phase'
                    series['message'] = 'Acquisition is believed to be func/bold (part-phase) because "MOSAIC" and "PHASE" are in the ImageType field of the metadata. Please modify if incorrect'
                else:
                    series['ModalityLabel'] = 'bold'
                    if series['EchoNumber']:
                        series_entities['echo'] = series['EchoNumber']
                        series['message'] = 'Acquisition is believed to be multiecho func/bold because "{}" is in the SeriesDescription (but not "sbref"), and EchoTime == {}. Please modify if incorrect'.format([x for x in func_keys if re.findall(x,SD)][0], series['EchoNumber'])
                if series['EchoNumber']:
                    series_entities['echo'] = series['EchoNumber']
                    series['message'] = 'Acquisition is believed to be multiecho func/bold because "{}" is in the SeriesDescription (but not "sbref"), and EchoTime == {}. Please modify if incorrect'.format([x for x in func_keys if re.findall(x,SD)][0], series['EchoNumber'])

        # Functional single band reference (sbref)
        elif 'sbref' in SD:
            series['ModalityLabel'] = 'sbref'

            if 'DIFFUSION' in series['ImageType']:
                series['DataType'] = 'dwi'
            else:
                series['DataType'] = 'func'

                if any(x in SD for x in func_rest_keys):
                    series_entities['task'] = 'rest'
                if series['EchoNumber']:
                    series_entities['echo'] = series['EchoNumber']
                series['message'] = 'Acquisition is believed to be func/sbref because "sbref" is in the SeriesDescription'

        # MP2RAGE/UNIT1
        elif 'mp2rage' in SD:
            series['DataType'] = 'anat'
            try:
                InversionTime = series['sidecar']['InversionTime']
            except:
                InversionTime = None

            if InversionTime:
                series['ModalityLabel'] = 'MP2RAGE'
                series['message'] = 'Acquisition is believed to be anat/mpr2rage, but "mp2rage" in in the SeriesDescription, and there is an InversionTime in the metadata. Please modify if incorrect.'

                if InversionTime < 1.0:
                    series_entities['inversion'] = 1
                else:
                    series_entities['inversion'] = 2

                # Look for echo number
                if 'EchoNumber' in series['sidecar']:
                    series_entities['echo'] = series['sidecar']['EchoNumber']

                # Determine part value (mag/phase)
                if '_e2.json' in series['json_path']:
                    series_entities['part'] = 'phase'
                else:
                    series_entities['part'] = 'mag'

            else:
                series['ModalityLabel'] = 'UNIT1'
                series['message'] = 'Acquisition is believed to be anat/UNIT1, but "mp2rage" in in the SeriesDescription, but there is no InversionTime in the metadata. Please modify if incorrect.'


        # T1w
        elif any(x in SD for x in t1w_keys):
            series['DataType'] = 'anat'
            series['ModalityLabel'] = 'T1w'
            if 'multiecho' in SD or 'echo' in SD:
                if 'MEAN' not in image_type:
                    series_entities['echo'] = series['EchoNumber']
            series['message'] = 'Acquisition is believed to be anat/T1w because "{}" is in the SeriesDescription. Please modify if incorrect'.format([x for x in t1w_keys if re.findall(x,SD)][0])

        # FLAIR
        elif any(x in SD for x in flair_keys):
            series['DataType'] = 'anat'
            series['ModalityLabel'] = 'FLAIR'
            series['message'] = 'Acquisition is believed to be anat/FLAIR because "{}" is in the SeriesDescription. Please modify if incorrect'.format([x for x in flair_keys if re.findall(x,SD)][0])

        # T2w
        elif any(x in SD for x in t2w_keys) and series['EchoTime'] > 100: #T2w acquisitions typically have EchoTime > 100ms
            series['DataType'] = 'anat'
            series['ModalityLabel'] = 'T2w'
            series['message'] = 'Acquisition is believed to be anat/T2w because "{}" is in the SeriesDescription and EchoTime > 100ms. Please modify if incorrect'.format([x for x in t2w_keys if re.findall(x,SD)][0])


        # Anatomical non-parametric
        elif any(x in SD for x in additional_anat_keys):
            series['DataType'] = 'anat'
            if 't2starw' in SD:
                series['ModalityLabel'] = 'T2starw'
                series['message'] = 'Acquisitions is believed to be anat/T2starw because "T2starw" is in the SeriesDescription. Please modify if incorrect'
            elif 'inplanet1' in SD:
                series['ModalityLabel'] = 'inplaneT1'
                series['message'] = 'Acquisitions is believed to be anat/inplaneT1 because "inplaneT1" is in the SeriesDescription. Please modify if incorrect'
            elif 'inplanet2' in SD:
                series['ModalityLabel'] = 'inplaneT2'
                series['message'] = 'Acquisitions is believed to be anat/inplaneT2 because "inplaneT2" is in the SeriesDescription. Please modify if incorrect'
            elif 'pdt2' in SD:
                series['ModalityLabel'] = 'PDT2'
                series['message'] = 'Acquisitions is believed to be anat/PDT2 because "PDT2" is in the SeriesDescription. Please modify if incorrect'
            elif 'pdw' in SD:
                series['ModalityLabel'] = 'PDw'
                series['message'] = 'Acquisitions is believed to be anat/PDw because "PDw" is in the SeriesDescription. Please modify if incorrect'


        # # anatomical parametric maps
       #  elif any(x in SD for x in anat_parametric_keys):
       #      series['DataType'] = 'anat'
       #      if 'chimap' in SD:
       #          series['ModalityLabel'] = 'Chimap'
       #          series['message'] = 'Acquisitions is believed to be anat/Chimap because "Chimap" is in the SeriesDescription. Please modify if incorrect'
       #      elif 't1rho' in SD:
       #          series['ModalityLabel'] = 'T1rho'
       #          series['message'] = 'Acquisitions is believed to be anat/T1rho because "T1rho" is in the SeriesDescription. Please modify if incorrect'
       #      elif 'mtsat' in SD:
       #          series['ModalityLabel'] = 'MTsat'
       #          series['message'] = 'Acquisitions is believed to be anat/MTsat because "MTsat" is in the SeriesDescription. Please modify if incorrect'
       #      else:
       #          modality_label = [x for x in anat_parametric_keys if re.findall(x,SD)][0]
       #          series['ModalityLabel'] = modality_label.split('map')[0].upper() + 'map'
       #          series['message'] = 'Acquisition is believed to be anat/{} because {} is in the SeriesDescription. Please modify if incorrect'.format(modality_label, modality_label)


        # Can't discern from SeriesDescription, try using ndim and number of volumes to see if this is a func/bold
        else:
            test = nib.load(series['nifti_path'])
            if test.ndim == 4 and test.shape[3] >= 50 and not any(x in series['ImageType'] for x in ['DERIVED','PERFUSION','DIFFUSION','ASL']):
                series['DataType'] = 'func'
                series['ModalityLabel'] = 'bold'
                series['message'] = 'SeriesDescription did not provide hints regarding the type of acquisition; however, it is believed to be a func/bold because it contains >= 50 volumes and is 4D. Please modify if incorrect'

            # Assume not BIDS-compliant acquisition unless user specifies so
            else:
                series['error'] = 'Acquisition cannot be resolved. Please determine whether or not this acquisition should be converted to BIDS'
                series['message'] = 'Acquisition is unknown because there is not enough adequate information, primarily in the SeriesDescription. Please modify if acquisition is desired for BIDS conversion, otherwise the acqusition will not be converted'
                series['br_type'] = 'exclude'


        # Combine DataType and ModalityLabel to form br_type variable (needed for internal brainlife.io storage)
        if 'exclude' not in series['br_type']:
            series['br_type'] = series['DataType'] + '/' + series['ModalityLabel']
        elif 'exclude' in series['br_type'] and 'localizer' not in series['br_type']:
            series['br_type'] = 'exclude'
        else:
            pass

        # Set non-normalized anatomicals to exclude
        if 'anat' in series['br_type'] and not any(x in ['DERIVED','NORM'] for x in series['ImageType']):
            series['br_type'] = 'exclude'
            series['error'] = 'Acquisition is a poor resolution {} (non-normalized); Please check to see if this {} acquisition should be converted to BIDS. Otherwise, this object will not be included in the BIDS output'.format(series['br_type'], series['br_type'])
            series['message'] = series['error']


        # Combine info above into dictionary, which will be displayed to user through the UI
        series_info = {"SeriesDescription": series['SeriesDescription'],
                       "series_idx": series['series_idx'],
                       "EchoTime": series['EchoTime'],
                       "ImageType": series['ImageType'],
                       "MultibandAccelerationFactor": series['MultibandAccelerationFactor'],
                       "entities": series_entities,
                       "type": series['br_type'],
                       "forType": series['forType'],
                       "error": series['error'],
                       "message": series['message'],
                       "object_indices": []
                        }
        series_list.append(series_info)


        print('Unique data acquisition file {}, Series Description {}, was determined to be {}'.format(series['nifti_path'], series['SeriesDescription'], series['br_type']))
        print('')
        print('')

    # Check sbref acquisitions to see that their corresponding func or dwi acquisitions are not excluded
    # If so, exclude the sbref as well
    for s in series_list:
        if 'sbref' in s['type']:
            SD = s['SeriesDescription']
            corresponding_file = [y for x,y in enumerate(series_list) if SD[:-6] == series_list[x]['SeriesDescription']][0]
            if corresponding_file['type'] == 'exclude':
                s['message'] = 'The corresponding file to this sbref is excluded, therefore this acquisition will also be excluded. Please modify if incorrect'
                s['type'] = 'exclude'

    # If series_entities items contain periods (not allowed in BIDS), replace them with "p"
    for s in series_list:
        for key, value in s['entities'].items():
            try:
                if '.' in value:
                    s['entities'][key] = value.replace('.', 'p')
            except:
                pass

    return series_list


def modify_objects_info(subject_protocol, series_list, series_seriesID_list):
    '''
    Takes list of dictionaries with key and unique information, and session it to
    determine the DataType and Modality labels of the unique acquisitions.
    Other information (e.g. run, acq, ce) will be determined if the data follows
    the ReproIn naming convention for SeriesDescriptions.

    Parameters
    ----------
    subject_protocol: list
        List of dictionary, containing pertinent information needed
        for the UI side of ezBIDS

    series_list: list
        List of dictionaries containing the series-level info for file naming,
        such as "acq","run","dir","ce", etc.

    series_seriesID_list: list
        List of numeric values, each one linked to a unique acquiistion in the
        series list. This is different from SeriesNumber, and is used to port
        info from the series-level down to the objects-level.

    Returns
    -------
    subject_protocol: list
        Same as above but with updated information
    '''

    section_ID = 1
    objects_data = []

    for p, protocol in enumerate(subject_protocol):
        SD = re.sub('[^A-Za-z0-9]+', '', protocol['SeriesDescription']).lower()
        previous_SD = re.sub('[^A-Za-z0-9]+', '', subject_protocol[p-1]['SeriesDescription']).lower()

        # Update section_ID information
        if p == 0:
            protocol['section_ID'] = section_ID

        elif any(x in SD for x in ['localizer','scout']) and not any(x in previous_SD for x in ['localizer','scout']):
            section_ID += 1
            protocol['section_ID'] = section_ID
        else:
            protocol['section_ID'] = section_ID


        protocol['headers'] = str(nib.load(protocol['nifti_path']).header).splitlines()[1:]

        image = nib.load(protocol['nifti_path'])
        object_img_array = image.dataobj
        if object_img_array.dtype not in ['<i2', '<u2']: # Weird issue where data array is RGB instead of intger
            protocol['exclude'] = True
            protocol['error'] = 'The data array is for this acquisition is improper, likely suggesting some issue with the corresponding DICOMS'
            protocol['message'] = protocol['error']
            protocol['br_type'] = 'exclude'
        else:
            if protocol['NumVolumes'] > 1:
                object_img_array = image.dataobj[..., 1]
            else:
                object_img_array = image.dataobj[:]

            if not os.path.isfile('{}.png'.format(protocol['nifti_path'][:-7])):

                slice_x = object_img_array[floor(object_img_array.shape[0]/2), :, :]
                slice_y = object_img_array[:, floor(object_img_array.shape[1]/2), :]
                slice_z = object_img_array[:, :, floor(object_img_array.shape[2]/2)]

                fig, axes = plt.subplots(1,3, figsize=(9,3))
                for i, slice in enumerate([slice_x, slice_y, slice_z]):
                    axes[i].imshow(slice.T, cmap="gray", origin="lower", aspect="auto")
                    axes[i].axis('off')
                plt.subplots_adjust(wspace=0, hspace=0)
                plt.savefig('{}.png'.format(protocol['nifti_path'][:-7]), bbox_inches='tight')


        index = series_seriesID_list.index(protocol['series_idx'])
        objects_entities = {'subject': '', 'session': '', 'run': '', 'task': '', 'direction': '', 'acquisition': '', 'ceagent': '', 'echo': '', 'fa': '', 'inversion': '', 'part': ''}

        # Make items list (part of objects list)
        items = []
        for item in protocol['paths']:
            if '.bval' in item:
                items.append({'path':item, 'name':'bval'})
            elif '.bvec' in item:
                items.append({'path':item, 'name':'bvec'})
            elif '.json' in item:
                items.append({'path':item, 'name':'json', 'sidecar':protocol['sidecar']})
            elif '.nii.gz' in item:
                items.append({'path':item, 'name':'nii.gz', 'headers':protocol['headers']})


        # Remove identifying information from sidecars
        remove_fields = ['SeriesInstanceUID', 'StudyInstanceUID',
                         'ReferringPhysicianName', 'StudyID', 'PatientName',
                         'PatientID', 'AccessionNumber', 'PatientBirthDate',
                         'PatientSex', 'PatientWeight']

        for remove in remove_fields:
            if remove in protocol['sidecar']:
                del protocol['sidecar'][remove]

        # Provide log output for acquisitions not deemed appropriate for BIDS conversion
        if protocol['exclude'] == True:
            print('')
            print('* {} (sn-{}) not recommended for BIDS conversion: {}'.format(protocol['SeriesDescription'], protocol['SeriesNumber'], protocol['error']))

        # Objects-level info for ezBIDS.json
        objects_info = {"series_idx": protocol['series_idx'],
                "PatientName": protocol['PatientName'],
                "PatientID": protocol['PatientID'],
                "PatientBirthDate": protocol['PatientBirthDate'],
                "AcquisitionDate": protocol['AcquisitionDate'],
                "pngPath": '{}.png'.format(protocol['nifti_path'][:-7]),
                "entities": objects_entities,
                "items": items,
                "analysisResults": {
                    "NumVolumes": protocol['NumVolumes'],
                    "errors": protocol['error'],
                    "filesize": protocol['filesize'],
                    "section_ID": protocol['section_ID']
                },
                "paths": protocol['paths']
              }
        objects_data.append(objects_info)

    return subject_protocol, objects_data


##################### Begin #####################

print('########################################')
print('Beginning conversion process of dataset')
print('########################################')
print('')

# Load list
orig_dir_list = pd.read_csv('list', header=None, sep='\n')

# Make modifications to dir_list (i.e. check that json files are good and add corresponding nifti (and bval/bvec) files)
dir_list = add_dirList(orig_dir_list)

# Determine variables data_list, data_list_unique_series, subjectIDs_info, and acquisition_dates
data_list, data_list_unique_series, subjectIDs_info, acquisition_dates = select_unique_data(dir_list)

# Determine series-level info
series_list = identify_series_info(data_list_unique_series)

# participantsColumn portion of ezBIDS.json
participantsColumn = {"sex": {"LongName": "gender", "Description": "generic gender field", "Levels": {"M": "male", "F": "female"}},
                      "age": {"LongName": "age", "Units": "years"}}

# Define a few variables that apply across the entire objects level
objects_list = []
subjects = [acquisition_dates[x]['subject'] for x in range(len(acquisition_dates))]
session = [acquisition_dates[x]['session'] for x in range(len(acquisition_dates))]
series_seriesID_list = [series_list[x]['series_idx'] for x in range(len(series_list))]

# Loop through all unique subjectIDs
for s in range(len(acquisition_dates)):

    if acquisition_dates[s]['session'] == '':
        print('')
        print('')
        print('Beginning conversion process for subject {} protocol acquisitions'.format(acquisition_dates[s]['subject']))
        print('-------------------------------------------------------------------')
        print('')

    else:
        print('')
        print('')
        print('Beginning conversion process for subject {}, session {} protocol acquisitions'.format(acquisition_dates[s]['subject'], acquisition_dates[s]['session']))
        print('-------------------------------------------------------------------')
        print('')

    # Get initial subject_protocol list from subjectsetting by subject/sessions
    subject_protocol = [x for x in data_list if x['subject'] == acquisition_dates[s]['subject'] and x['session'] == acquisition_dates[s]['session']]

    # Update subject_protocol based on object-level checks
    subject_protocol, objects_data = modify_objects_info(subject_protocol, series_list, series_seriesID_list)

    objects_list.append(objects_data)

objects_list = [x for y in objects_list for x in y]

# Rename ezBIDS localizer designators to "exclude"
for s in range(len(series_list)):
    if series_list[s]['type'] == 'exclude (localizer)':
        series_list[s]['type'] = 'exclude'

    series_list[s]['object_indices'] = [x for x in range(len(objects_list)) if objects_list[x]['series_idx'] == series_list[s]['series_idx']]

# Convert infor to dictionary
ezBIDS = {"subjects": subjectIDs_info,
          "participantsColumn": participantsColumn,
          "series": series_list,
          "objects": objects_list
          }

# Write dictionary to ezBIDS.json
ezBIDS_file_name = 'ezBIDS.json'
with open(ezBIDS_file_name, 'w') as fp:
    json.dump(ezBIDS, fp, indent=3)



















